{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# util\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import networkx as nx\n",
    "import scipy.sparse as sp\n",
    "import sys\n",
    "\n",
    "\n",
    "def parse_index_file(filename):\n",
    "    \"\"\"Parse index file.\"\"\"\n",
    "    index = []\n",
    "    for line in open(filename):\n",
    "        index.append(int(line.strip()))\n",
    "    return index\n",
    "\n",
    "\n",
    "def sample_mask(idx, l):\n",
    "    \"\"\"Create mask.\"\"\"\n",
    "    mask = np.zeros(l)\n",
    "    mask[idx] = 1\n",
    "    return np.array(mask, dtype=np.bool)\n",
    "\n",
    "\n",
    "def load_data(dataset_str):\n",
    "    names = ['x', 'y', 'tx', 'ty', 'allx', 'ally', 'graph']\n",
    "    objects = []\n",
    "    for i in range(len(names)):\n",
    "        with open(\"/home/zihe-leon/Desktop/RobustGCN-master/data/ind.{}.{}\".format(dataset_str, names[i]), 'rb') as f:\n",
    "            if sys.version_info > (3, 0):\n",
    "                objects.append(pkl.load(f, encoding='latin1'))\n",
    "            else:\n",
    "                objects.append(pkl.load(f))\n",
    "\n",
    "    x, y, tx, ty, allx, ally, graph = tuple(objects)\n",
    "    test_idx_reorder = parse_index_file(\"/home/zihe-leon/Desktop/RobustGCN-master/data/ind.{}.test.index\".format(dataset_str))\n",
    "    test_idx_range = np.sort(test_idx_reorder)\n",
    "    if dataset_str == 'citeseer':\n",
    "        # Fix citeseer dataset (there are some isolated nodes in the graph)\n",
    "        # Find isolated nodes, add them as zero-vecs into the right position\n",
    "        test_idx_range_full = range(min(test_idx_reorder), max(test_idx_reorder)+1)\n",
    "        tx_extended = sp.lil_matrix((len(test_idx_range_full), x.shape[1]))\n",
    "        tx_extended[test_idx_range-min(test_idx_range), :] = tx\n",
    "        tx = tx_extended\n",
    "        ty_extended = np.zeros((len(test_idx_range_full), y.shape[1]))\n",
    "        ty_extended[test_idx_range-min(test_idx_range), :] = ty\n",
    "        ty = ty_extended\n",
    "\n",
    "    features = sp.vstack((allx, tx)).tolil()\n",
    "    features[test_idx_reorder, :] = features[test_idx_range, :]\n",
    "    adj = nx.adjacency_matrix(nx.from_dict_of_lists(graph))\n",
    "\n",
    "    labels = np.vstack((ally, ty))\n",
    "    labels[test_idx_reorder, :] = labels[test_idx_range, :]\n",
    "\n",
    "    idx_test = test_idx_range.tolist()\n",
    "    idx_train = range(len(y))\n",
    "    idx_val = range(len(y), len(y)+500)\n",
    "\n",
    "    train_mask = sample_mask(idx_train, labels.shape[0])\n",
    "    val_mask = sample_mask(idx_val, labels.shape[0])\n",
    "    test_mask = sample_mask(idx_test, labels.shape[0])\n",
    "\n",
    "    y_train = np.zeros(labels.shape)\n",
    "    y_val = np.zeros(labels.shape)\n",
    "    y_test = np.zeros(labels.shape)\n",
    "    y_train[train_mask, :] = labels[train_mask, :]\n",
    "    y_val[val_mask, :] = labels[val_mask, :]\n",
    "    y_test[test_mask, :] = labels[test_mask, :]\n",
    "\n",
    "    return adj, features, y_train, y_val, y_test, train_mask, val_mask, test_mask, labels\n",
    "\n",
    "\n",
    "def sparse_to_tuple(sparse_mx):\n",
    "    \"\"\"Convert sparse matrix to tuple representation.\"\"\"\n",
    "    def to_tuple(mx):\n",
    "        if not sp.isspmatrix_coo(mx):\n",
    "            mx = mx.tocoo()\n",
    "        coords = np.vstack((mx.row, mx.col)).transpose()\n",
    "        values = mx.data\n",
    "        shape = mx.shape\n",
    "        return coords, values, shape\n",
    "\n",
    "    if isinstance(sparse_mx, list):\n",
    "        for i in range(len(sparse_mx)):\n",
    "            sparse_mx[i] = to_tuple(sparse_mx[i])\n",
    "    else:\n",
    "        sparse_mx = to_tuple(sparse_mx)\n",
    "\n",
    "    return sparse_mx\n",
    "\n",
    "def perturb_features(features, ratio):\n",
    "    features = features.toarray()\n",
    "    pert_idx = np.random.choice(len(features), int(ratio*len(features)))\n",
    "    perturbed = []\n",
    "    for row in range(len(features)):\n",
    "        if row in pert_idx:\n",
    "            arr = features[row]\n",
    "            # flip_mask = [0]*int(0.8*len(arr)) + [1]*(len(arr)-int(0.8*len(arr)))\n",
    "            # np.random.shuffle(flip_mask)\n",
    "            # flip_mask = np.array(flip_mask, dtype=bool)\n",
    "            p_idx = np.random.choice(len(arr), int(0.2*len(arr)))\n",
    "            arr[p_idx] = 1-arr[p_idx]\n",
    "            # np.logical_not(arr, where=flip_mask, out=arr)    \n",
    "            perturbed.append(arr)\n",
    "        else:\n",
    "            arr = features[row]\n",
    "            perturbed.append(arr)\n",
    "    perturbed_features = sp.csr_matrix(perturbed)\n",
    "    return perturbed_features\n",
    "\n",
    "\n",
    "def preprocess_features(features):\n",
    "    \"\"\"Row-normalize feature matrix and convert to tuple representation\"\"\"\n",
    "    # print(features[0])\n",
    "    rowsum = np.array(features.sum(1))\n",
    "    r_inv = np.power(rowsum, -1).flatten()\n",
    "    r_inv[np.isinf(r_inv)] = 0.\n",
    "    r_mat_inv = sp.diags(r_inv)\n",
    "    features = r_mat_inv.dot(features)\n",
    "    return sparse_to_tuple(features)\n",
    "\n",
    "def normalize_adj(adj, alpha):\n",
    "    \"\"\"Symmetrically normalize adjacency matrix.\"\"\"\n",
    "    adj = sp.coo_matrix(adj)\n",
    "    rowsum = np.array(adj.sum(1))\n",
    "    d_inv_sqrt = np.power(rowsum, alpha).flatten()\n",
    "    d_inv_sqrt[np.isinf(d_inv_sqrt)] = 0.\n",
    "    d_mat_inv_sqrt = sp.diags(d_inv_sqrt)\n",
    "    return adj.dot(d_mat_inv_sqrt).transpose().dot(d_mat_inv_sqrt).tocoo()\n",
    "\n",
    "def preprocess_adj(adj, alpha):\n",
    "    \"\"\"Preprocessing of adjacency matrix for simple GCN model and conversion to tuple representation.\"\"\"\n",
    "    adj_normalized = normalize_adj(adj + sp.eye(adj.shape[0]), alpha)\n",
    "    return sparse_to_tuple(adj_normalized)\n",
    "\n",
    "\n",
    "def construct_feed_dict(features, support, labels, labels_mask, placeholders, adj):\n",
    "    \"\"\"Construct feed dictionary.\"\"\"\n",
    "    feed_dict = dict()\n",
    "    feed_dict.update({placeholders['labels']: labels})\n",
    "    feed_dict.update({placeholders['labels_mask']: labels_mask})\n",
    "    feed_dict.update({placeholders['features']: features})\n",
    "    feed_dict.update({placeholders['support'][i]: support[i] for i in range(len(support))})\n",
    "    feed_dict.update({placeholders['num_features_nonzero']: features[1].shape})\n",
    "    return feed_dict\n",
    "\n",
    "def masked_softmax_cross_entropy(preds, labels, mask):\n",
    "    loss = tf.nn.softmax_cross_entropy_with_logits(logits=preds, labels=labels)\n",
    "    mask = tf.cast(mask, dtype=tf.float32)\n",
    "    mask /= tf.reduce_mean(mask)\n",
    "    loss *= mask\n",
    "    return tf.reduce_mean(loss)\n",
    "\n",
    "\n",
    "def masked_accuracy(preds, labels, mask):\n",
    "    correct_prediction = tf.equal(tf.argmax(preds, 1), tf.argmax(labels, 1))\n",
    "    accuracy_all = tf.cast(correct_prediction, tf.float32)\n",
    "    mask = tf.cast(mask, dtype=tf.float32)\n",
    "    mask /= tf.reduce_mean(mask)\n",
    "    accuracy_all *= mask\n",
    "    return tf.reduce_mean(accuracy_all)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-08 14:09:29.270026: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-08 14:09:29.390014: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-04-08 14:09:29.797269: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/zihe-leon/anaconda3/envs/gcn3/lib/\n",
      "2023-04-08 14:09:29.797313: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/zihe-leon/anaconda3/envs/gcn3/lib/\n",
      "2023-04-08 14:09:29.797317: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "# layers\n",
    "from gcn.inits import *\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_eager_execution()\n",
    "\n",
    "flags = tf.app.flags\n",
    "FLAGS = flags.FLAGS\n",
    "\n",
    "_LAYER_UIDS = {}\n",
    "\n",
    "\n",
    "def get_layer_uid(layer_name=''):\n",
    "    if layer_name not in _LAYER_UIDS:\n",
    "        _LAYER_UIDS[layer_name] = 1\n",
    "        return 1\n",
    "    else:\n",
    "        _LAYER_UIDS[layer_name] += 1\n",
    "        return _LAYER_UIDS[layer_name]\n",
    "\n",
    "\n",
    "def sparse_dropout(x, keep_prob, noise_shape):\n",
    "    \"\"\"Dropout for sparse tensors.\"\"\"\n",
    "    random_tensor = keep_prob\n",
    "    random_tensor += tf.random_uniform(noise_shape)\n",
    "    dropout_mask = tf.cast(tf.floor(random_tensor), dtype=tf.bool)\n",
    "    pre_out = tf.sparse_retain(x, dropout_mask)\n",
    "    return pre_out * (1./keep_prob)\n",
    "\n",
    "\n",
    "def dot(x, y, sparse=False):\n",
    "    if sparse:\n",
    "        res = tf.sparse_tensor_dense_matmul(x, y)\n",
    "    else:\n",
    "        res = tf.matmul(x, y)\n",
    "    return res\n",
    "\n",
    "\n",
    "class Layer(object):\n",
    "    def __init__(self, **kwargs):\n",
    "        allowed_kwargs = {'name', 'logging'}\n",
    "        for kwarg in kwargs.keys():\n",
    "            assert kwarg in allowed_kwargs, 'Invalid keyword argument: ' + kwarg\n",
    "        name = kwargs.get('name')\n",
    "        if not name:\n",
    "            layer = self.__class__.__name__.lower()\n",
    "            name = layer + '_' + str(get_layer_uid(layer))\n",
    "        self.name = name\n",
    "        self.vars = {}\n",
    "        logging = kwargs.get('logging', False)\n",
    "        self.logging = logging\n",
    "        self.sparse_inputs = False\n",
    "\n",
    "    def _call(self, inputs):\n",
    "        return inputs\n",
    "\n",
    "    def __call__(self, inputs):\n",
    "        with tf.name_scope(self.name):\n",
    "            if self.logging and not self.sparse_inputs:\n",
    "                tf.summary.histogram(self.name + '/inputs', inputs)\n",
    "            outputs = self._call(inputs)\n",
    "            if self.logging:\n",
    "                tf.summary.histogram(self.name + '/outputs', outputs)\n",
    "            return outputs\n",
    "\n",
    "    def _log_vars(self):\n",
    "        for var in self.vars:\n",
    "            tf.summary.histogram(self.name + '/vars/' + var, self.vars[var])\n",
    "\n",
    "class GGCL_F(Layer):\n",
    "    \"\"\"GGCL: the input is feature\"\"\"\n",
    "    def __init__(self, input_dim, output_dim, placeholders, dropout=0.,\n",
    "                 sparse_inputs=False, bias=False,\n",
    "                 featureless=False, **kwargs):\n",
    "        super(GGCL_F, self).__init__(**kwargs)\n",
    "\n",
    "        if dropout:\n",
    "            self.dropout = placeholders['dropout']\n",
    "        else:\n",
    "            self.dropout = 0.\n",
    "\n",
    "        self.support = placeholders['support']\n",
    "        self.sparse_inputs = sparse_inputs\n",
    "        self.featureless = featureless\n",
    "        self.bias = bias\n",
    "        self.output_dim = output_dim\n",
    "        self.num_features_nonzero = placeholders['num_features_nonzero']\n",
    "\n",
    "        with tf.variable_scope(self.name + '_vars'):\n",
    "            self.vars['weights_0'] = glorot([input_dim, output_dim], name='weights_0')\n",
    "            if self.bias:\n",
    "                self.vars['bias'] = zeros([output_dim], name='bias')\n",
    "\n",
    "        if self.logging:\n",
    "            self._log_vars()\n",
    "\n",
    "    def _call(self, inputs):\n",
    "        x = inputs\n",
    "        if self.sparse_inputs:\n",
    "            x = sparse_dropout(x, 1-self.dropout, self.num_features_nonzero)\n",
    "        else:\n",
    "            x = tf.nn.dropout(x, 1-self.dropout)\n",
    "        supports = list()\n",
    "        i = 0\n",
    "        if not self.featureless:\n",
    "            pre_sup = dot(x, self.vars['weights_' + str(i)],\n",
    "                          sparse=self.sparse_inputs)\n",
    "        else:\n",
    "            pre_sup = self.vars['weights_' + str(i)]\n",
    "        support = dot(self.support[i], pre_sup, sparse=True)\n",
    "        supports.append(support)\n",
    "        dim = int(self.output_dim / 2)\n",
    "        mean_vector = tf.nn.elu(tf.slice(pre_sup, [0, 0], [-1, dim]))\n",
    "        var_vector = tf.nn.relu(tf.slice(pre_sup, [0, dim], [-1, dim]))\n",
    "        self.vars['mean'] = mean_vector\n",
    "        self.vars['var'] = var_vector\n",
    "        node_weight = tf.exp(-var_vector*FLAGS.para_var)\n",
    "        mean_out = dot(self.support[0], mean_vector * node_weight, sparse=True)\n",
    "        var_out = dot(self.support[1], var_vector * node_weight * node_weight, sparse=True)\n",
    "        print(\"*******************************************************************\")\n",
    "        print(var_vector)\n",
    "        output = tf.concat([mean_out, var_out], axis=1)\n",
    "        return output\n",
    "\n",
    "class GGCL_D(Layer):\n",
    "    \"\"\"GGCL: the input is distribution\"\"\"\n",
    "    def __init__(self, input_dim, output_dim, placeholders, dropout=0.,\n",
    "                 sparse_inputs=False, bias=False,\n",
    "                 featureless=False, **kwargs):\n",
    "        super(GGCL_D, self).__init__(**kwargs)\n",
    "\n",
    "        if dropout:\n",
    "            self.dropout = placeholders['dropout']\n",
    "        else:\n",
    "            self.dropout = 0.\n",
    "        self.support = placeholders['support']\n",
    "        self.sparse_inputs = sparse_inputs\n",
    "        self.featureless = featureless\n",
    "        self.bias = bias\n",
    "        self.dim = int(input_dim / 2)\n",
    "        self.num_features_nonzero = placeholders['num_features_nonzero']\n",
    "\n",
    "        with tf.variable_scope(self.name + '_vars'):\n",
    "            self.vars['weights_mean'] = glorot([self.dim, output_dim], name='weights_mean')\n",
    "            self.vars['weights_var'] = glorot([self.dim, output_dim], name='weights_var')\n",
    "            if self.bias:\n",
    "                self.vars['bias'] = zeros([output_dim], name='bias')\n",
    "\n",
    "        if self.logging:\n",
    "            self._log_vars()\n",
    "\n",
    "    def _call(self, inputs):\n",
    "        x = inputs\n",
    "        if self.sparse_inputs:\n",
    "            x = sparse_dropout(x, 1-self.dropout, self.num_features_nonzero)\n",
    "        else:\n",
    "            x = tf.nn.dropout(x, 1-self.dropout)\n",
    "        mean_vector = tf.slice(x, [0, 0], [-1, self.dim])\n",
    "        var_vector = tf.slice(x, [0, self.dim], [-1, self.dim])\n",
    "        mean_vector = tf.nn.elu(dot(mean_vector, self.vars['weights_mean']))\n",
    "        var_vector = tf.nn.relu(dot(var_vector, self.vars['weights_var']))\n",
    "        node_weight = tf.exp(-var_vector*FLAGS.para_var)\n",
    "        mean_out = dot(self.support[0], mean_vector * node_weight, sparse=True)\n",
    "        var_out = dot(self.support[1], var_vector * node_weight * node_weight, sparse=True)\n",
    "        self.vars['var'] = var_out\n",
    "        sample_v = tf.random_normal(tf.shape(var_out), 0, 1,\n",
    "                                    dtype=tf.float32)\n",
    "        mean_out = mean_out + (tf.math.sqrt(var_out + 1e-8) * sample_v)\n",
    "        self.vars['mean'] = tf.nn.softmax(mean_out)\n",
    "        output = mean_out\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "from layers import *\n",
    "from utils import *\n",
    "\n",
    "flags = tf.app.flags\n",
    "FLAGS = flags.FLAGS\n",
    "\n",
    "\n",
    "class Model(object):\n",
    "    def __init__(self, **kwargs):\n",
    "        allowed_kwargs = {'name', 'logging'}\n",
    "        for kwarg in kwargs.keys():\n",
    "            assert kwarg in allowed_kwargs, 'Invalid keyword argument: ' + kwarg\n",
    "        name = kwargs.get('name')\n",
    "        if not name:\n",
    "            name = self.__class__.__name__.lower()\n",
    "        self.name = name\n",
    "\n",
    "        logging = kwargs.get('logging', False)\n",
    "        self.logging = logging\n",
    "\n",
    "        self.vars = {}\n",
    "        self.placeholders = {}\n",
    "\n",
    "        self.layers = []\n",
    "        self.activations = []\n",
    "\n",
    "        self.inputs = None\n",
    "        self.outputs = None\n",
    "\n",
    "        self.loss = 0\n",
    "        self.accuracy = 0\n",
    "        self.optimizer = None\n",
    "        self.opt_op = None\n",
    "\n",
    "    def _build(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def build(self):\n",
    "        with tf.variable_scope(self.name):\n",
    "            self._build()\n",
    "        self.activations.append(self.inputs)\n",
    "        for layer in self.layers:\n",
    "            hidden = layer(self.activations[-1])\n",
    "            self.activations.append(hidden)\n",
    "        self.outputs = self.activations[-1]\n",
    "        variables = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=self.name)\n",
    "        self.vars = {var.name: var for var in variables}\n",
    "        self._loss()\n",
    "        self._accuracy()\n",
    "        self.opt_op = self.optimizer.minimize(self.loss)\n",
    "\n",
    "    def predict(self):\n",
    "        pass\n",
    "\n",
    "    def _loss(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def _accuracy(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def save(self, sess=None):\n",
    "        if not sess:\n",
    "            raise AttributeError(\"TensorFlow session not provided.\")\n",
    "        saver = tf.train.Saver(self.vars)\n",
    "        save_path = saver.save(sess, \"tmp/%s.ckpt\" % self.name)\n",
    "        print(\"Model saved in file: %s\" % save_path)\n",
    "\n",
    "    def load(self, sess=None):\n",
    "        if not sess:\n",
    "            raise AttributeError(\"TensorFlow session not provided.\")\n",
    "        saver = tf.train.Saver(self.vars)\n",
    "        save_path = \"tmp/%s.ckpt\" % self.name\n",
    "        saver.restore(sess, save_path)\n",
    "        print(\"Model restored from file: %s\" % save_path)\n",
    "\n",
    "class RGCN(Model):\n",
    "    def __init__(self, placeholders, input_dim, **kwargs):\n",
    "        super(RGCN, self).__init__(**kwargs)\n",
    "\n",
    "        self.inputs = placeholders['features']\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = placeholders['labels'].get_shape().as_list()[1]\n",
    "        self.placeholders = placeholders\n",
    "        self.optimizer = tf.train.AdamOptimizer(learning_rate=FLAGS.learning_rate)\n",
    "        self.build()\n",
    "\n",
    "    def _loss(self):\n",
    "        self.loss += FLAGS.para_l2 * (tf.nn.l2_loss(self.layers[0].vars['weights_0']) )\n",
    "        mean = self.layers[0].vars['mean']\n",
    "        var = self.layers[0].vars['var']\n",
    "        KL_divergence = 0.5 * tf.reduce_mean(tf.square(mean) + var - tf.log(1e-8 + var) - 1, 1)\n",
    "        KL_divergence = tf.reduce_sum(KL_divergence)\n",
    "        self.loss += FLAGS.para_kl * KL_divergence\n",
    "        self.vars = self.layers[1].vars['var']\n",
    "        self.mean = self.layers[1].vars['mean']\n",
    "        self.loss += masked_softmax_cross_entropy(self.outputs, self.placeholders['labels'],\n",
    "                                                  self.placeholders['labels_mask'])\n",
    "\n",
    "    def _accuracy(self):\n",
    "        mean_vector = tf.slice(self.outputs, [0, 0], [-1, self.output_dim])\n",
    "        self.accuracy = masked_accuracy(mean_vector, self.placeholders['labels'],\n",
    "                                        self.placeholders['labels_mask'])\n",
    "\n",
    "    def _build(self):\n",
    "        self.layers.append(GGCL_F(input_dim=self.input_dim,\n",
    "                                            output_dim=FLAGS.hidden,\n",
    "                                            placeholders=self.placeholders,\n",
    "                                            dropout=True,\n",
    "                                            sparse_inputs=True,\n",
    "                                            logging=self.logging))\n",
    "\n",
    "        self.layers.append(GGCL_D(input_dim=FLAGS.hidden,\n",
    "                                            output_dim=self.output_dim,\n",
    "                                            placeholders=self.placeholders,\n",
    "                                            dropout=True,\n",
    "                                            logging=self.logging))\n",
    "\n",
    "    def predict(self):\n",
    "        return tf.nn.softmax(self.outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnrecognizedFlagError",
     "evalue": "Unknown command line flag 'Session.signature_scheme'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnrecognizedFlagError\u001b[0m                     Traceback (most recent call last)",
      "\u001b[1;32m/home/zihe-leon/Desktop/RobustGCN-master/src/model.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 38>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/zihe-leon/Desktop/RobustGCN-master/src/model.ipynb#W2sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m tf\u001b[39m.\u001b[39mcompat\u001b[39m.\u001b[39mv1\u001b[39m.\u001b[39mflags\u001b[39m.\u001b[39mDEFINE_string(\u001b[39m'\u001b[39m\u001b[39mhb\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/zihe-leon/Desktop/RobustGCN-master/src/model.ipynb#W2sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m \u001b[39m# Load data\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/zihe-leon/Desktop/RobustGCN-master/src/model.ipynb#W2sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m adj, features, y_train, y_val, y_test, train_mask, val_mask, test_mask, label \u001b[39m=\u001b[39m load_data(FLAGS\u001b[39m.\u001b[39;49mdataset)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/zihe-leon/Desktop/RobustGCN-master/src/model.ipynb#W2sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m \u001b[39m# add noise to the data\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/zihe-leon/Desktop/RobustGCN-master/src/model.ipynb#W2sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m features \u001b[39m=\u001b[39m perturb_features(features, \u001b[39m0\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/gcn3/lib/python3.9/site-packages/tensorflow/python/platform/flags.py:81\u001b[0m, in \u001b[0;36m_FlagValuesWrapper.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[39m# To maintain backwards compatibility, implicitly parse flags when reading\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \u001b[39m# a flag.\u001b[39;00m\n\u001b[1;32m     80\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m wrapped\u001b[39m.\u001b[39mis_parsed():\n\u001b[0;32m---> 81\u001b[0m   wrapped(_sys\u001b[39m.\u001b[39;49margv)\n\u001b[1;32m     82\u001b[0m \u001b[39mreturn\u001b[39;00m wrapped\u001b[39m.\u001b[39m\u001b[39m__getattr__\u001b[39m(name)\n",
      "File \u001b[0;32m~/anaconda3/envs/gcn3/lib/python3.9/site-packages/absl/flags/_flagvalues.py:650\u001b[0m, in \u001b[0;36mFlagValues.__call__\u001b[0;34m(self, argv, known_only)\u001b[0m\n\u001b[1;32m    648\u001b[0m \u001b[39mfor\u001b[39;00m name, value \u001b[39min\u001b[39;00m unknown_flags:\n\u001b[1;32m    649\u001b[0m   suggestions \u001b[39m=\u001b[39m _helpers\u001b[39m.\u001b[39mget_flag_suggestions(name, \u001b[39mlist\u001b[39m(\u001b[39mself\u001b[39m))\n\u001b[0;32m--> 650\u001b[0m   \u001b[39mraise\u001b[39;00m _exceptions\u001b[39m.\u001b[39mUnrecognizedFlagError(\n\u001b[1;32m    651\u001b[0m       name, value, suggestions\u001b[39m=\u001b[39msuggestions)\n\u001b[1;32m    653\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmark_as_parsed()\n\u001b[1;32m    654\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalidate_all_flags()\n",
      "\u001b[0;31mUnrecognizedFlagError\u001b[0m: Unknown command line flag 'Session.signature_scheme'"
     ]
    }
   ],
   "source": [
    "# train\n",
    "import time\n",
    "import tensorflow.compat.v1 as tf\n",
    "# tf.disable_eager_execution()\n",
    "tf.config.run_functions_eagerly(True)\n",
    "tf.enable_eager_execution()\n",
    "from utils import *\n",
    "from models import RGCN\n",
    "import random\n",
    "# Set random seed\n",
    "seed = 123\n",
    "np.random.seed(seed)\n",
    "tf.set_random_seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "# Settings\n",
    "flags = tf.app.flags\n",
    "FLAGS = flags.FLAGS\n",
    "flags.DEFINE_string('dataset', 'cora', 'Dataset string.')  # 'cora', 'citeseer', 'pubmed'\n",
    "flags.DEFINE_float('learning_rate', 0.01, 'Initial learning rate.')\n",
    "flags.DEFINE_integer('epochs', 2, 'Number of epochs to train.')\n",
    "flags.DEFINE_integer('hidden', 32, 'Number of units in hidden layer.')\n",
    "flags.DEFINE_float('dropout', 0.6, 'Dropout rate (1 - keep probability).')\n",
    "flags.DEFINE_float('para_var', 1, 'Parameter of variance-based attention')\n",
    "flags.DEFINE_float('para_kl', 5e-4, 'Parameter of kl regularization')\n",
    "flags.DEFINE_float('para_l2', 5e-4, 'Parameter for l2 loss.')\n",
    "flags.DEFINE_integer('early_stopping', 20, 'Tolerance for early stopping (# of epochs).')\n",
    "\n",
    "tf.compat.v1.flags.DEFINE_string('ip','','')\n",
    "tf.compat.v1.flags.DEFINE_string('stdin','','')\n",
    "tf.compat.v1.flags.DEFINE_string('control','','')\n",
    "tf.compat.v1.flags.DEFINE_string('hb','','')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Load data\n",
    "adj, features, y_train, y_val, y_test, train_mask, val_mask, test_mask, label = load_data(FLAGS.dataset)\n",
    "# add noise to the data\n",
    "features = perturb_features(features, 0)\n",
    "features = preprocess_features(features)\n",
    "\n",
    "support = [preprocess_adj(adj, -0.5), preprocess_adj(adj, -1.0)]\n",
    "placeholders = {\n",
    "    'support': [tf.sparse_placeholder(tf.float32) for _ in range(2)],\n",
    "    'features': tf.sparse_placeholder(tf.float32, shape=tf.constant(features[2], dtype=tf.int64)),\n",
    "    'labels': tf.placeholder(tf.float32, shape=(None, y_train.shape[1])),\n",
    "    'labels_mask': tf.placeholder(tf.int32),\n",
    "    'dropout': tf.placeholder_with_default(0., shape=()),\n",
    "    'num_features_nonzero': tf.placeholder(tf.int32),\n",
    "}\n",
    "model = RGCN(placeholders, input_dim=features[2][1], logging=True)\n",
    "sess = tf.Session()\n",
    "def evaluate(features, support, labels, mask, placeholders, adj):\n",
    "    t_test = time.time()\n",
    "    feed_dict_val = construct_feed_dict(features, support, labels, mask, placeholders, adj)\n",
    "    outs_val = sess.run([model.loss, model.accuracy], feed_dict=feed_dict_val)\n",
    "    return outs_val[0], outs_val[1], (time.time() - t_test)\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "cost_val = []\n",
    "for epoch in range(FLAGS.epochs):\n",
    "    t = time.time()\n",
    "    feed_dict = construct_feed_dict(features, support, y_train, train_mask, placeholders, adj)\n",
    "    feed_dict.update({placeholders['dropout']: FLAGS.dropout})\n",
    "    outs = sess.run([model.opt_op, model.loss, model.accuracy, model.vars], feed_dict=feed_dict)\n",
    "    cost, _, duration = evaluate(features, support, y_val, val_mask, placeholders, adj)\n",
    "    cost_val.append(cost)\n",
    "    # Print results\n",
    "    print(\"Epoch:\", '%04d' % (epoch + 1), \"train_loss=\", \"{:.5f}\".format(outs[1]),\n",
    "          \"train_acc=\", \"{:.5f}\".format(outs[2]), \"time=\", \"{:.5f}\".format(time.time() - t))\n",
    "    if epoch > FLAGS.early_stopping and cost_val[-1] > np.mean(cost_val[-(FLAGS.early_stopping+1):-1]):\n",
    "        print(\"Early stopping...\")\n",
    "        break\n",
    "print(\"Optimization Finished!\")\n",
    "\n",
    "# Testing\n",
    "_, features, _, _, _, _, _, _, _ = load_data(FLAGS.dataset)\n",
    "features = preprocess_features(features)\n",
    "test_cost, test_acc, test_duration = evaluate(features, support, y_test, test_mask, placeholders, adj)\n",
    "print(\"Test set results:\", \"cost=\", \"{:.5f}\".format(test_cost),\n",
    "      \"accuracy=\", \"{:.5f}\".format(test_acc), \"time=\", \"{:.5f}\".format(test_duration))\n",
    "\n",
    "print(tf.Session().run(tf.constant([1,2,3])))\n",
    "\n",
    "print(tf.Session().run(model.vars))\n",
    "\n",
    "# print(model.vars.eval(session = tf.Session()))\n",
    "import tensorflow as tf2\n",
    "\n",
    "# tf2.print(model.vars, output_stream=sys.stderr)\n",
    "\n",
    "tensor = tf2.range(10)\n",
    "tf2.print(tensor)\n",
    "print(\"~~~~~~~~~~~~~~~~~~~~~~~~\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('gcn3')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2e7b7b5e1a181dd957b9f7885452852dc79e790ae39cec452ad265aa1fdb9dc8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
